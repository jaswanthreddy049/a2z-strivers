{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5nXScWOX0S71G7UsjF125",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaswanthreddy049/a2z-strivers/blob/main/GenAIcohort_May2025_PromptEng_jaswanth_reddy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT_1\n",
        "\n"
      ],
      "metadata": {
        "id": "303sklgHhnJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq litellm langchain_groq"
      ],
      "metadata": {
        "id": "7C5xhPimhmqp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "from langchain_groq import ChatGroq\n",
        "from litellm import completion"
      ],
      "metadata": {
        "id": "QurUYAVFyohr",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = userdata.get('demo')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")"
      ],
      "metadata": {
        "id": "guLrChQbygIU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "  #define model\n",
        "  model=\"groq/llama3-70b-8192\"\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  #call responses\n",
        "  response = completion(\n",
        "      model=model,\n",
        "      messages=messages\n",
        "  )\n",
        "\n",
        "  return response['choices'][0]['message']['content'] or \"\"\n"
      ],
      "metadata": {
        "id": "Y4XmE_cvx5Ay"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=f\"\"\"Black..... holes—those mysterious cosmic phenomena—are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha### have dived deeply into the “science”\n",
        "\n",
        "of these objects, uncovering fascinating insights! According to Rothwell’s research (2021), black holes form when massive stars burn ^^^^through their fuel & collapse under gravity until they reach a singularity—a point of (nearly) infinite density, where physics bReak dOwn.\n",
        "\n",
        "Sinha’s studies focus on the event horizon, or the “point of no return”; any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation—a theoretical ....concept from Stephen Hawking—suggesting that black holes.... emit small amounts of energy...., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities!!!!. Together, Rothwell and Sinha’s studies hint at bridging quantum mechanics w/ general relativity—fields otherwise tough to reconcile!\n",
        "\n",
        "Remember to clean the text.\"\"\"\n",
        "\n",
        "prompt=f\"\"\"\n",
        "        you will bw provided with a text in between triple codes text is ''' {text}''',summaries the given information in 100 words the text should be clean.\n",
        "        every line should be of equal length\"\"\"\n",
        "response=get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbOzxriqgp66",
        "outputId": "f7aab599-38fc-489a-a2e3-6ef0aa17b6a9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a 100-word summary of the text:\n",
            "\n",
            "Black holes are regions in space with intense gravitational forces that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have delved into the science of these objects. Rothwell's research shows that black holes form when massive stars collapse under gravity, reaching a singularity. Sinha's studies focus on the event horizon, where matter and light are trapped, and Hawking Radiation suggests black holes emit energy, slowly losing mass. Their studies hint at bridging quantum mechanics and general relativity, fields tough to reconcile. The research provides fascinating insights into the mysterious nature of black holes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review=f\"\"\"I absolutely loved the new update—it’s so user-friendly and fast!\"\"\"\n",
        "prompt=f\"\"\"\n",
        "      you will be given with an example review and your task is to classify the review as positive or negative or neutral.\n",
        "      here is the review '''{review}'''.\"\"\"\n",
        "response=get_response(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "gTUINW-bkQW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a6b08c-f8a8-4c31-96d6-935acd044fc7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the language used in the review, I would classify it as **POSITIVE**. The words \"absolutely loved\", \"user-friendly\", and \"fast\" all have positive connotations, indicating that the reviewer is very happy with the new update.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userreq=f\"\"\"get me candidates with 2 years experience in python and flask and candidate should academic grades should more than 70 percentage ready to work in hyderabad\"\"\"\n",
        "prompt=f\"\"\"generate a mangodb query in pymango formate to filter the resumes with this query'''{userreq}'''\"\"\"\n",
        "response=get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "dd3lWntByLvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09937229-3d5c-44bd-ed2a-3f2fa340a0c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the query in PyMongo format:\n",
            "```\n",
            "query = {\n",
            "    \"$and\": [\n",
            "        {\"experience\": {\"$gte\": 2}},\n",
            "        {\"skills\": {\"$all\": [\"python\", \"flask\"]}},\n",
            "        {\"academic_grades\": {\"$gt\": 70}},\n",
            "        {\"ready_to_work_in\": \"hyderabad\"}\n",
            "    ]\n",
            "}\n",
            "```\n",
            "Here's a breakdown of the query:\n",
            "\n",
            "* `\"$and\"`: This is a logical operator to combine multiple filter clauses.\n",
            "* `{\"experience\": {\"$gte\": 2}}`: This clause filters candidates with at least 2 years of experience. The `$gte` operator is used to specify a minimum value.\n",
            "* `{\"skills\": {\"$all\": [\"python\", \"flask\"]}}`: This clause filters candidates who have both \"python\" and \"flask\" skills. The `$all` operator is used to specify an array of values that must be present in the `skills` field.\n",
            "* `{\"academic_grades\": {\"$gt\": 70}}`: This clause filters candidates with academic grades greater than 70%. The `$gt` operator is used to specify a minimum value.\n",
            "* `{\"ready_to_work_in\": \"hyderabad\"}`: This clause filters candidates who are ready to work in Hyderabad.\n",
            "\n",
            "Note: I assume that the fields `experience`, `skills`, `academic_grades`, and `ready_to_work_in` exist in the MongoDB collection, and that the data types of these fields are correct. If the field names or data types differ, you may need to adjust the query accordingly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT 2"
      ],
      "metadata": {
        "id": "HvAj1e86hKeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq litellm langchain-groq langchain langchain-community langgraph"
      ],
      "metadata": {
        "id": "B5SjBoZoBOjO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('demo')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "sg50_MA7Tul_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import List\n",
        "from litellm import completion\n",
        "from langchain.agents import initialize_agent, Tool, AgentType"
      ],
      "metadata": {
        "id": "3GSfThjX5xcJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\", #\"llama-3.1-8b-instant\",\n",
        "    temperature=0, # range of temperature variable is from 0(least artistic) to 1(most artistic/enhanced)\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "E98waGQtTwxT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import List\n",
        "class emotionalOutput(BaseModel):\n",
        "    \"\"\"\n",
        "    Defines the structured output schema that the LLM must follow.\n",
        "\n",
        "    Fields:\n",
        "    - Patient's emotional state (e.g., fear, anxious, calm)\n",
        "    - score: emotion intensity score from 1 to 5 as an integer\n",
        "    \"\"\"\n",
        "    sentiment: str = Field(description=\"emotion of the patient in the conversation\")\n",
        "    score: int = Field(description=\"patient emotional intensity score  on a scale of 1 to 5\")\n",
        "\n",
        "class Communicationsummary(BaseModel):\n",
        "    \"\"\"\n",
        "    Defines the structured output schema that the LLM must follow.\n",
        "\n",
        "    Fields:\n",
        "    - summary :List of summaries and urgency assessment\n",
        "    \"\"\"\n",
        "    improvements: List[str] = Field(description=\"List of summarie of the conversation and urgency oof the patient\")\n"
      ],
      "metadata": {
        "id": "ev7uycPNrjwh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "parser = PydanticOutputParser(pydantic_object=emotionalOutput)\n",
        "@tool\n",
        "def analyze_patient_emotion(conversation: str):\n",
        "    \"\"\"\n",
        "    Analyzes a patient-agent conversation to extract:\n",
        "    1. The patients emotion (e.g.,cool,fear,anxious etc..)\n",
        "    2. A patients emotion score (1 to 5)\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full conversation between the agent and the patient.\n",
        "\n",
        "    Returns:\n",
        "    - emtionOutput: Contains emotion and score, parsed and validated by the Pydantic model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prompt tells the LLM exactly what to do and restricts it from returning anything extra.\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in analyzing healthcare conversations.\n",
        "\n",
        "    Analyze the given conversation {conversation} between a agent and a patient and extract the following:\n",
        "    1. patient emotion (clam,fear, anxious, etc.)\n",
        "    2. Emotional intensity score (1 to 5)\n",
        "    3. Short summary of patient complaint and urgency level\n",
        "    Strictly respond following the below schema:\n",
        "    {parser.get_format_instructions()}\n",
        "    \"\"\"\n",
        "\n",
        "    #using chatgroq from langchain\n",
        "    response = llm.invoke(prompt)\n",
        "    cleaned_output = response.content.strip()\n",
        "    return cleaned_output\n"
      ],
      "metadata": {
        "id": "c6XKEdqwflys"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_tools = [\n",
        "    Tool(\n",
        "        name=\"emotionAnalysisTool\",\n",
        "        func=analyze_patient_emotion,\n",
        "        description=\"\"\"Use this tool to analyze the patient emotion (e.g.,fear,calm,anxious) and\n",
        "        give a emotion intensity score (1–5). \"\"\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "#Bind the LLM with your tools\n",
        "llm_with_new_tools = llm.bind_tools(new_tools)"
      ],
      "metadata": {
        "id": "xIZzdF_waUMS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_react_agent(llm_with_new_tools, new_tools)"
      ],
      "metadata": {
        "id": "76jl1DMPxLz3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Agent: Good morning! Thank you for reaching out to CareConnect. How can I assist you today?\n",
        "Patient: I’ve been having chest pain for the past two days, and it’s getting worse.\n",
        "Agent: I’m really sorry to hear that. Let’s look into it right away. Can you describe the pain a bit more?\n",
        "Patient: This is the second time in a month this has happened. It’s really worrying and exhausting.\n",
        "Agent: I understand your concern. I’ll schedule a priority consultation and flag this for immediate review.\n",
        "Patient: Okay. Please make sure this gets taken seriously this time.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GmtGjGyQrT7O"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=f\"what is customer emotion intensity score in {conversation}?\")]})\n",
        "response[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "l8U8osd4z3W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfd005f-23c6-45b9-f55a-6dc63a963c3a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The patient's emotion intensity score is 4, with the dominant emotion being anxious.\n"
          ]
        }
      ]
    }
  ]
}